{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, UpSampling2D, Conv2D, Concatenate, Input\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.utils import plot_model\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "from data_augmentation import TransformImageMask\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "im_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_csv('data/metadata.csv')\n",
    "\n",
    "print('Number of examples is',total_data.shape[0])\n",
    "num_classes = 120\n",
    "\n",
    "train_data, val_data = train_test_split(total_data, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_imgs(ids, inputstr='data/train/{}_{:02d}.jpg'):\n",
    "    imgs = []\n",
    "    \n",
    "    for idx in ids:\n",
    "        for i in range(16):\n",
    "            img = cv2.imread(inputstr.format(idx, i+1))\n",
    "            if img is not None:\n",
    "                # print('--->', inputstr.format(idx, i+1))\n",
    "                img = cv2.resize(img, (im_size, im_size))\n",
    "                imgs.append(img)\n",
    "    \n",
    "    return np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_process_data(data, to_augment=False):\n",
    "    \n",
    "    data_imgs = load_imgs(data['id'], 'data/train/{}_{:02d}.jpg')\n",
    "    data_imgs = data_imgs / 255.0\n",
    "    data_masks = np.expand_dims(load_imgs(data['id'], 'data/train_masks/{}_{:02d}_mask.jpg').mean(axis=3), axis=3)\n",
    "    data_masks = data_masks / 255.0\n",
    "    \n",
    "    if to_augment:\n",
    "        list_imgs = []\n",
    "        list_masks = []\n",
    "\n",
    "        for i in range(data_imgs.shape[0]):\n",
    "            img = data_imgs[i, :, :, :]\n",
    "            mask = data_masks[i, :, :, :]\n",
    "            img, mask = TransformImageMask(img, mask)\n",
    "            list_imgs = list_imgs + img\n",
    "            list_masks = list_masks + mask\n",
    "        data_imgs = np.array(list_imgs)\n",
    "        list_imgs = []\n",
    "        data_masks = np.array(list_masks)\n",
    "        list_masks = []\n",
    "        \n",
    "    return (data_imgs, data_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "zz = load_and_process_data(total_data[:100], True)\n",
    "img = zz[0][0,:,:,:]\n",
    "mask = zz[1][0,:,:,:]\n",
    "print(zz[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(zz[1][5,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = load_and_process_data(total_data[:100])\n",
    "print(aa[1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_accuracy(X, Y, model):\n",
    "    pred_classes = model.predict_classes(X, verbose=0, batch_size = 20)\n",
    "    actual_classes = np.argmax(Y, axis=1)\n",
    "    return np.sum(pred_classes == actual_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_accuracy(model):\n",
    "    s = 0\n",
    "    l = 0\n",
    "    val_imgs, val_labels = load_and_process_data(val_data)\n",
    "    predicted = model.predict(val_imgs, verbose=1)\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    actual = [dict_dogs[x] for x in val_data['breed']]\n",
    "\n",
    "    for i in range(len(predicted)):\n",
    "        l = l+1\n",
    "        if predicted[i] == actual[i]:\n",
    "            s = s+1\n",
    "    return(s/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_training(num_samples, num_iter, train_data, model, batch_size = None, epochs = None, to_augment = False):\n",
    "    if batch_size is None:\n",
    "        batch_size = 32\n",
    "    if epochs is None:\n",
    "        epochs = 1\n",
    "    acc_vs_epoch = []\n",
    "    for niter in range(num_iter):\n",
    "        for i in range( int(float(len(train_data)) / float(num_samples) + 1.0)):\n",
    "            gc.collect()\n",
    "            print('Loading data from', i*num_samples, 'to', (i+1)*num_samples)\n",
    "            train_imgs, train_labels = load_and_process_data(train_data [ i*num_samples: (i+1)*num_samples ], to_augment)\n",
    "            print(train_imgs.shape, train_labels.shape)\n",
    "            model.fit(train_imgs, train_labels, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "        #val_acc = validation_accuracy(model)\n",
    "        #acc_vs_epoch.append(val_acc)\n",
    "        #print('Validation Accuracy:', val_acc)\n",
    "        \n",
    "    return acc_vs_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n",
    "model2 = model_vgg.output\n",
    "#model2 = MaxPooling2D(pool_size=(2,2))(model2)\n",
    "model2 = Convolution2D(256, 3, 3, border_mode='same', init='glorot_uniform', activation='relu')(model2)\n",
    "model2 = UpSampling2D(size = (2, 2))(model2)\n",
    "model2 = Convolution2D(64, 3, 3, border_mode='same', init='glorot_uniform', activation='relu')(model2)\n",
    "model2 = UpSampling2D(size = (2, 2))(model2)\n",
    "model2 = Convolution2D(32, 3, 3, border_mode='same', init='glorot_uniform', activation='relu')(model2)\n",
    "model2 = UpSampling2D(size = (2, 2))(model2)\n",
    "model2 = Convolution2D(16, 3, 3, border_mode='same', init='glorot_uniform', activation='relu')(model2)\n",
    "model2 = UpSampling2D(size = (2, 2))(model2)\n",
    "model2 = Convolution2D(8, 3, 3, border_mode='same', init='glorot_uniform', activation='relu')(model2)\n",
    "model2 = UpSampling2D(size = (2, 2))(model2)\n",
    "model2 = Convolution2D(1, 3, 3, border_mode='same', init='glorot_uniform', activation='sigmoid')(model2)\n",
    "model2 = Model(inputs=model_vgg.input, outputs=model2)\n",
    "\n",
    "for layer in model_vgg.layers:\n",
    "    layer.trainable = False\n",
    "model2.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_training(1001, 10, train_data[:1000], model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#img, mask = load_and_process_data(train_data[:100])\n",
    "i = 10\n",
    "print(img.shape, mask[0, :, :, 0].shape)\n",
    "plt.imshow(mask[i, :, :, 0])\n",
    "plt.figure()\n",
    "plt.imshow(img[i, :, :, :])\n",
    "plt.figure()\n",
    "\n",
    "outimage = model3.predict(img[i:i+1, :, :, :])\n",
    "plt.imshow(outimage[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.save_weights('vgg_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Convolution2D(4, 3, 3, border_mode='same', input_shape=(im_size, im_size, 3), activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Convolution2D(16, 3, 3, border_mode='same', activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "model3.add(UpSampling2D(size=(2, 2)))\n",
    "model3.add(Convolution2D(16, 3, 3, border_mode='same', activation='relu'))\n",
    "model3.add(UpSampling2D(size=(2, 2)))\n",
    "model3.add(Convolution2D(4, 3, 3, border_mode='same', activation='relu'))\n",
    "model3.add(UpSampling2D(size=(2, 2)))\n",
    "model3.add(Convolution2D(1, 3, 3, border_mode='same', activation='sigmoid'))\n",
    "\n",
    "model3.compile(loss=\"binary_crossentropy\", optimizer=\"adagrad\")\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_layer(input_layer, num_filter):\n",
    "    layer = Conv2D(num_filter, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "    layer = Conv2D(num_filter, (3, 3), padding='same', activation='relu')(layer)\n",
    "    maxpool_layer = MaxPooling2D((2, 2))(layer)\n",
    "    return maxpool_layer, layer\n",
    "\n",
    "def up_layer(input_layer_down, input_layer_side, num_filter):\n",
    "    layer = UpSampling2D(size=(2, 2))(input_layer_down)\n",
    "    layer = Conv2D(num_filter, (3, 3), padding='same', activation='relu')(layer)\n",
    "    layer = Concatenate(axis=3)([input_layer_side, layer])\n",
    "    layer = Conv2D(num_filter, (3, 3), padding='same', activation='relu')(layer)\n",
    "    layer = Conv2D(num_filter, (3, 3), padding='same', activation='relu')(layer)\n",
    "    \n",
    "    return layer\n",
    "\n",
    "input_layer = Input([im_size, im_size, 3])\n",
    "\n",
    "down1, cross1 = down_layer(input_layer, 8)\n",
    "down2, cross2 = down_layer(down1, 16)\n",
    "down3, cross3 = down_layer(down2, 32)\n",
    "down4, cross4 = down_layer(down3, 64)\n",
    "_, cross5 = down_layer(down4, 128)\n",
    "\n",
    "\n",
    "up1 = up_layer(cross5, cross4, 64)\n",
    "up2 = up_layer(up1, cross3, 32)\n",
    "up3 = up_layer(up2, cross2, 16)\n",
    "up4 = up_layer(up3, cross1, 8)\n",
    "\n",
    "out = Conv2D(1, (3, 3), padding='same', activation='sigmoid')(up4)\n",
    "\n",
    "unet_model = Model(input_layer, out)\n",
    "unet_model.compile(loss=\"binary_crossentropy\", optimizer=\"adagrad\")\n",
    "\n",
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(128, 1, train_data, unet_model, batch_size=32, epochs = 5, to_augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask = load_and_process_data(train_data[:100])\n",
    "i = 3\n",
    "print(img.shape, mask[0, :, :, 0].shape)\n",
    "plt.imshow(mask[i, :, :, 0])\n",
    "plt.figure()\n",
    "plt.imshow(img[i, :, :, :])\n",
    "plt.figure()\n",
    "\n",
    "outimage = unet_model.predict(img[i:i+1, :, :, :])\n",
    "plt.imshow(outimage[0, :, :, 0]>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unet_model.save('unet_augment_15.dat')\n",
    "unet_model.save_weights('unet2_augment_weights_15.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = img[i:i+1, :, :, :].reshape(256, 256, 3)\n",
    "for c in range(3):\n",
    "    ii[:, :, c] = ii[:, :, c]*(outimage[0, :, :, 0]>0.5)\n",
    "print(ii.shape)\n",
    "plt.imshow(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coeff(img1, img2):\n",
    "    a1 = img1.reshape(-1)\n",
    "    a2 = img2.reshape(-1)\n",
    "    \n",
    "    return (2*np.sum(a1*a2)) / (a1.sum() + a2.sum())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice_coefficient(model):\n",
    "    val_imgs, val_masks = load_and_process_data(val_data)\n",
    "    val_predicted = model.predict(val_imgs)\n",
    "\n",
    "    return(dice_coeff(val_masks, val_predicted))\n",
    "print(calc_dice_coefficient(unet_model))\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "m = 0\n",
    "s = 0\n",
    "for var, obj in globals().items():\n",
    "    #print(var, sys.getsizeof(obj))\n",
    "    m = max(m, sys.getsizeof(obj))\n",
    "    s = s + sys.getsizeof(obj)\n",
    "    \n",
    "print(m, s)\n",
    "#del val_imgs, val_masks, val_predicted\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "unet_model = load_model('unet_augment_15.dat')\n",
    "unet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
